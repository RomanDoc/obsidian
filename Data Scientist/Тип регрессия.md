Тип машинного обучения предназначенный для предсказания новых числовых значений на основе имеющихся данных
#### Линейная регрессия
Вид регрессии представляющая собой линию (или плоскость в многомерном пространстве), которая описывается формулой:
$$ y = w0 + w1*x1\ +\ ...\ +\ wi*xi $$
где:
y - целевая переменная (зависимая переменная),
w0 ... wi - коэффициенты,
x1 ... xi - признаки целевой переменной (независимые переменные).
##### Обучение модели
Для примера воспользуемся библиотекой `sklearn`
**Загружаем необходимы библиотеки:**
```python
# модуль для разделения выборки на тренеровочную и тестовую
from sklearn.model_selection import train_test_split 
# модуль для обучения древовидной модели
from sklearn.linear_model import LinearRegression
# загрузим метрки для определения качества линейной регрессии
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
```
где:
`mean_absolute_error`  - среднее абсолютная разность между целевым значением и предсказанным значением (средняя абсолютная ошибка).
`mean_squared_error` - среднее квадратов разности между целевым значение и предсказанным значением (средняя квадратичная ошибка).
`r2_score` - коэффициент детерминации.
```python
# копируем данные в новый датафрейм
df_prep = df.copy()
# разбиваем данные на тренеровочную и тестовую выборки
train, test = train_test_split(df_prep, train_size=0.7, random_state=17)
X_train = train.drop(['target_column'], axis=1)
y_train = train['target_column']
X_test = test.drop(['target_column'], axis=1)
y_test = test['target_column']
# обучим модель линейной регрессии
lm = LinearRegression()
lm.fit(X_train, y_train)
# предскажем значения на основе обученной модели
train_predict = lm.predict(X_train)
test_predict = lm.predict(X_test)
# проверим качество модели на метриках
print(f'mae train l1: {mean_absolute_error(y_train, train_predict)}')
print(f'mae test l1: {mean_absolute_error(y_test, test_predict)}')

print(f'mse train l1: {mean_squared_error(y_train, train_predict)}')
print(f'mse test l1: {mean_squared_error(y_test, test_predict)}')

print(f'r2 train l1: {r2_score(y_train, train_predict)}')
print(f'r2 test l1: {r2_score(y_test, test_predict)}')
```
##### Регуляризация линейной регрессии
Регуляризация предназначена для регулирования влияния признаков на предсказания целевой переменной. Она может уменьшить влияния или свести его к нулю (выключить определенную переменную). Различают несколько видов регуляризации это L1 и L2. Математическая суть состоит в том, что добавляется штраф к функции ошибок. При L1 этот штраф равен произведению сумме всех коэффициентов модели на значение лямбда. При L2 регуляризации штраф равен произведению сумме квадратов всех коэффициентов модели на значение лямбда.  В практическом смысле различия между L1 и L2 регуриляции следующие: 
**L1**
- хорошо работает на простых моделях
- устойчива к выбросам
- не затратна по вычислительным мощностям
- позволяет производить отбор параметров за счет обнуления их.
**L2**
- хорошо работает на сложных моделях
- не устойчива к выбросам
- затратна по вычислительным мощностям
- не производит отбор параметров, более плавное снижение действия параметра на модель
- необходимо нормализация параметров модели (приведения их к одному масштабу)
##### Реализация регуляризации
- **L1**
```python
# импортирование L1 регуляризации
from sklearn.linear_model import Lasso
# обучение модели
lm_lasso = Lasso(alpha=0.1, random_state=17)
lm_lasso.fit(X_train, y_train)
# предсказание целевой переменной на основе обученой модели
lm_lasso_predict_train = lm_lasso.predict(X_train)
lm_lasso_predict_test = lm_lasso.predict(X_test)
# проверка качества модели на метриках
print(f'mae train l1: {mean_absolute_error(y_train, lm_lasso_predict_train)}')
print(f'mae test l1: {mean_absolute_error(y_test, lm_lasso_predict_test)}')

print(f'mse train l1: {mean_squared_error(y_train, lm_lasso_predict_train)}')
print(f'mse test l1: {mean_squared_error(y_test, lm_lasso_predict_test)}')

print(f'r2 train l1: {r2_score(y_train, lm_lasso_predict_train)}')
print(f'r2 test l1: {r2_score(y_test, lm_lasso_predict_test)}')
```
- **L2**
```python
# импортирование L регуляризации
from sklearn.linear_model import Ridge
from sklearn import preprocessing
# нормализация данных
nor = preprocessing.normalize(df_prep, axis=0)
df_norm = pd.DataFrame(nor, columns=df.columns)
# разбиваем данные на тренеровочную и тестовую выборки
train, test = train_test_split(df_norm, train_size=0.7, random_state=17)
X_train = train.drop(['target_column'], axis=1)
y_train = train['target_column']
X_test = test.drop(['target_column'], axis=1)
y_test = test['target_column']
# обучение модели
lm_ridge = Ridge(alpha=0.1, random_state=17)
lm_ridge.fit(X_train, y_train)
# предсказание целевой переменной на основе обученой модели
lm_ridge_predict_train = lm_ridge.predict(X_train)
lm_ridge_predict_test = lm_ridge.predict(X_test)
# проверка качества модели на метриках
print(f'mae train l1: {mean_absolute_error(y_train, lm_ridge_predict_train)}')
print(f'mae test l1: {mean_absolute_error(y_test, lm_ridge_predict_test)}')

print(f'mse train l1: {mean_squared_error(y_train, lm_ridge_predict_train)}')
print(f'mse test l1: {mean_squared_error(y_test, lm_ridge_predict_test)}')

print(f'r2 train l1: {r2_score(y_train, lm_ridge_predict_train)}')
print(f'r2 test l1: {r2_score(y_test, lm_ridge_predict_test)}')
```
