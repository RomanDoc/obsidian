Суть метода заключается в том, что бы отнести классифицируемый объект к тому классу, к которому принадлежат ближайшие к нему объекты обучающей выборки.
Алгоритм метода:
- вычислить расстояния до каждого из объектов обучающей выборки.
- отобрать k - объектов расстояние до которых меньше всего
- класс классифицируемого объекта относиться к тому классу у которого наибольшее количество k ближайших соседей.
##### Преимущества
- простота реализации
- интерпретируемость результата
##### Недостатки
- неустойчивость к шуму, погрешностям
- отсутствуют настраиваемые параметры
- необходимо хранить всю выборку целиком(ленивое обучение)
##### Обучение модели
Для примера воспользуемся библиотекой `sklearn`
**Загружаем необходимы библиотеки:**
```Python
import pandas as pd
# модуль для разделения выборки на тренеровочную и тестовую
from sklearn.model_selection import train_test_split
# модуль для обучения k - ближащие соседи
from sklearn.neighbors import KNeighborsClassifier
# загрузим метреки для оценки качества модели
from sklearn.metrics import confusion_matrix, classification_report
```
где: 
`confusion_matrix` - матрица ошибок вида
`[TN, FP`
`FN, TP]`
`classification_report` - классификационный отчет показывающий такие параметры
точность (`precision`), полнота (`recall`), f - мера, accuracy и т. д.
- Точность (`precision`) имеет следующий вид:
$$precission = TP / (TP + FP) *100\%$$
точность показывает количество правильно предсказанных положительных значений из всех истино положительных значений.
- Полнота (`reccal`) имеет следующий вид:
$$reccal = TP / (TP + FN) *100\%$$
полнота показывает количество правильно предсказанных положительных значений из всех предсказанных положительных значений.
- `f - мера` имеет следующий вид:
$$F = (1+b2) * (precision*recall) / (b2*precision + recall)$$
0 < b < 1 - приоритет точности (`precision`)
b > 1 - приоритет полноты (`recall`)
b = 1 - сбалансированная f - мера
f - мера показывает значение объединенных  метрик точности и полноты
```Python
# копируем данные в новый датафрейм
df_prep = df.copy()
# разбиваем данные на тренеровочную и тестовую выборки
train, test = train_test_split(df_prep, train_size=0.7, random_state=17)
X_train = train.drop(['target_column'], axis=1)
y_train = train['target_column']
X_test = test.drop(['target_column'], axis=1)
y_test = test['target_column']
# обучим модель линейной регрессии
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
# предскажем значения на основе обученной модели
train_predict = knn.predict(X_train)
test_predict = knn.predict(X_test)
# проверим качество модели с помощью classification_report
classification_report(y_train, train_predict)
classification_report(y_test, test_predict)
# отчет покажет общее качество модели, точность и полноту по каждому из предсказаных класов
# выведим матрцу ошибок
confusion_matrix(y_train, train_predict)
confusion_matrix(y_test, test_predict)
```
