Древовидная структура в программирование - это специальная структура данных, состоящая из узлов (node) и листьев (leaf). 
В этой структуре узел - это вопрос, лист - искомый результат (класс). Изначальный верхний узел называется корневым. Через череду таких вопросов данные рассеиваются по листам. В каком-то роде узлы напоминают структуру принятия решений if - else. Если данные отвечают одному условия идут по одной ветки, если другому, то попадают в другу ветку. Все это происходит до тех пор пока данные не дойдут до своих листьев.
Задача ML инженера создать (подобрать) самую эффективную структуру дерева.
#### Обучение модели
Для примера воспользуемся библиотекой `sklearn`
**Загружаем необходимы библиотеки:**
```python
# модуль для разделения выборки на тренеровочную и тестовую
from sklearn.model_selection import train_test_split 
# модуль для обучения древовидной модели
from sklearn.tree import DecisionTreeClassifier


# создадим копию датасета, что бы неиспортит изначальные данные
df_prep = df.copy()

# создаем две переменные в одну (х) записываем весь датасет без целевой 
# переменной, в другую (y) записываем только колонку с целевой переменной
x = df_prep.drop(['target_column'], axis=1)
y = df_prep.target_column
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)
# test_size - объем тестовой выборки (30%), random_state - фиксирует точку 
# отсчета для выборки на тренеровочную и тестовую

# обучаем модель
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)

# делаем предсказания на основе обученой модели
predicted_train = clf.predict(X_train)
predicted_test = clf.predict(X_test)

# определить коэффициенты важности для фичей
clf.feature_importances_

# выводим коэффициенты важности с их названиями
f_imp_list = list(zip(X_train.columns, clf.feature_importances_))
f_imp_list.sort(key=lambda x: x[1], reverse=True)

```

